{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from cltk.corpus.utils.importer import CorpusImporter\n",
    "\n",
    "\n",
    "my_latin_downloader = CorpusImporter('latin')\n",
    "my_latin_downloader.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_latin_downloader.import_corpus('latin_text_latin_library')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cltk.corpus.utils.importer import CorpusImporter\n",
    "corpus_importer = CorpusImporter('latin')\n",
    "corpus_importer.import_corpus('latin_models_cltk')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.stop.latin import STOPS_LIST\n",
    "\n",
    "\n",
    "\n",
    "directory = 'texts/non-comedy/poetry'\n",
    "dir_list = os.listdir(directory)\n",
    "\n",
    "for dir in dir_list:\n",
    "    file_path = directory + '/' + dir\n",
    "    with open(file_path, encoding='utf-8-sig') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    jv_replacer = JVReplacer()\n",
    "    text = jv_replacer.replace(text.lower())\n",
    "    # text = re.sub(r'\\{(.|\\n)+?\\}', '', text)\n",
    "    # text = re.sub(r'\\d[\\d-]*?', '', text)    \n",
    "    text = re.sub(r'[A-Z]+?\\.?', '', text)\n",
    "    # text = re.sub(r'<(.|\\n)+?>', '', text)\n",
    "    # text = re.sub(r'\\[(.|\\n)+?\\]', '', text)\n",
    "    # text = re.sub(r'\\((.|\\n)+?\\)', '', text)\n",
    "    text = re.sub(r'[-â€”*]', '', text)\n",
    "\n",
    "    word_tokenizer = WordTokenizer('latin')\n",
    "    text_tokens = word_tokenizer.tokenize(text)\n",
    "    text_tokens = [x for x in text_tokens if x not in \n",
    "                   ['.', ',', ':', ';', '?', '!'] \n",
    "                   and x]\n",
    "    \n",
    "    lemmatizer = LemmaReplacer('latin')\n",
    "    lemmata = lemmatizer.lemmatize(text_tokens)\n",
    "    \n",
    "    with open('texts/lemmatized/non-comedy/poetry/' + os.path.splitext(dir)[0] + '_lemmatized' + os.path.splitext(dir)[1], 'w', encoding='utf-8') as f:\n",
    "        f.write(' '.join(lemmata))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "directory = 'texts/lemmatized/comedy'\n",
    "dir_list = os.listdir(directory)\n",
    "\n",
    "non_comedy_poetry_lemmata = []\n",
    "for dir in dir_list:\n",
    "    file_path = directory + '/' + dir\n",
    "    print(file_path)\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = text.split()\n",
    "    non_comedy_poetry_lemmata.append(text)\n",
    "\n",
    "with open('lemmata/comedy.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(non_comedy_poetry_lemmata, f, indent=4)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from cltk.stop.latin import STOPS_LIST\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "with open('lemmata/comedy.json', encoding='utf-8') as f:\n",
    "    comedy_lemmata = json.loads(f.read())[0]\n",
    "with open('lemmata/non-comedy_poetry.json', encoding='utf-8') as f:\n",
    "    non_comedy_lemmata = json.loads(f.read())[0]\n",
    "with open('lemmata/non-comedy_prose.json', encoding='utf-8') as f:\n",
    "    non_comedy_lemmata.extend(json.loads(f.read())[0])\n",
    "comedy_lemmata = [x for x in comedy_lemmata if x not in ['amph', 'sos', 'merc', 'alc']]\n",
    "\n",
    "# comedy_lemmata = [x for x in comedy_lemmata if x not in STOPS_LIST]\n",
    "# non_comedy_lemmata = [x for x in non_comedy_lemmata if x not in STOPS_LIST]\n",
    "\n",
    "comedy_amount = len(comedy_lemmata)\n",
    "non_comedy_amount = len(non_comedy_lemmata)\n",
    "for i in Counter(comedy_lemmata).most_common(10):\n",
    "    print(i[0], round(i[1]*(10**6)/9801), 'ipm')\n",
    "print()\n",
    "for i in Counter(non_comedy_lemmata).most_common(10):\n",
    "    print(i[0], round(i[1]*(10**6)/35234), 'ipm')\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "pprint(Counter(comedy_lemmata).most_common(100))\n",
    "pprint(Counter(non_comedy_lemmata).most_common(100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import re\n",
    "from _collections import OrderedDict\n",
    "from cltk.tag.pos import POSTag\n",
    "tagger = POSTag('latin')\n",
    "\n",
    "\n",
    "comedy_freq_dict = {}\n",
    "non_comedy_freq_dict = {}\n",
    "\n",
    "for lemma in comedy_lemmata:\n",
    "    if lemma not in comedy_freq_dict:\n",
    "        comedy_freq_dict[lemma] = 0\n",
    "    comedy_freq_dict[lemma] += 1\n",
    "for i in comedy_freq_dict:\n",
    "    comedy_freq_dict[i] = round(comedy_freq_dict[i]*(10**6)/9801, 3)\n",
    "    \n",
    "for i in comedy_freq_dict:\n",
    "    lemma = re.sub('\\d', '', i)\n",
    "    number = comedy_freq_dict[i]\n",
    "    comedy_freq_dict[i] = (None, comedy_freq_dict[i])\n",
    "    analysis = tagger.tag_ngram_123_backoff(lemma)[0][1]\n",
    "    if analysis:\n",
    "        if not analysis.startswith('-'):\n",
    "            comedy_freq_dict[i] = (analysis[0], number)        \n",
    "\n",
    "comedy_freq_dict = list(comedy_freq_dict.items())\n",
    "comedy_freq_dict.sort(key=lambda x: x[1][1], reverse=True)\n",
    "comedy_freq_dict = OrderedDict(comedy_freq_dict)\n",
    "\n",
    "for lemma in non_comedy_lemmata:\n",
    "    if lemma not in non_comedy_freq_dict:\n",
    "        non_comedy_freq_dict[lemma] = 0\n",
    "    non_comedy_freq_dict[lemma] += 1\n",
    "for i in non_comedy_freq_dict:\n",
    "    non_comedy_freq_dict[i] = round(non_comedy_freq_dict[i]*(10**6)/35234, 3)\n",
    "    \n",
    "for i in non_comedy_freq_dict:\n",
    "    lemma = re.sub('\\d', '', i)\n",
    "    number = non_comedy_freq_dict[i]\n",
    "    non_comedy_freq_dict[i] = (None, non_comedy_freq_dict[i])\n",
    "    analysis = tagger.tag_ngram_123_backoff(lemma)[0][1]\n",
    "    if analysis:\n",
    "        if not analysis.startswith('-'):\n",
    "            non_comedy_freq_dict[i] = (analysis[0], number)            \n",
    "    \n",
    "non_comedy_freq_dict = list(non_comedy_freq_dict.items())\n",
    "non_comedy_freq_dict.sort(key=lambda x: x[1][1], reverse=True)\n",
    "non_comedy_freq_dict = OrderedDict(non_comedy_freq_dict)\n",
    "print(non_comedy_freq_dict)\n",
    "\n",
    "    \n",
    "with open('comedy_freq_dict.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(comedy_freq_dict, f, indent=4)\n",
    "\n",
    "with open('non_comedy_freq_dict.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(non_comedy_freq_dict, f, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'NA': 333027.01100001443, 'P': 48158.35, 'V': 108560.34500000006, 'D': 62646.66000000002, 'A': 69788.78600000002, 'U': 11019.284000000001, 'N': 101418.18700000002, 'C': 4081.216000000001, 'R': 6121.820999999995, 'E': 1428.425, 'M': 1428.424, 'T': 102.03}\n{'P': 39961.40099999999, 'NA': 383635.6969999377, 'U': 22591.814, 'V': 64710.22399999996, 'A': 80036.32600000006, 'D': 39280.24999999993, 'N': 138020.10400000325, 'R': 4541.076999999995, 'C': 2412.443, 'M': 1560.993, 'E': 1078.5049999999999, 'T': 851.4509999999996}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('comedy_freq_dict.json', encoding='utf-8') as f:\n",
    "    comedy_freq_dict = json.loads(f.read())\n",
    "with open('non_comedy_freq_dict.json', encoding='utf-8') as f:\n",
    "    non_comedy_freq_dict = json.loads(f.read())\n",
    "\n",
    "comedy_pos_dict = {}\n",
    "for i in comedy_freq_dict:\n",
    "    if comedy_freq_dict[i][0]:\n",
    "        if comedy_freq_dict[i][0] not in comedy_pos_dict:\n",
    "            comedy_pos_dict[comedy_freq_dict[i][0]] = 0\n",
    "        comedy_pos_dict[comedy_freq_dict[i][0]] += comedy_freq_dict[i][1]\n",
    "    else:\n",
    "        if 'NA' not in comedy_pos_dict:\n",
    "            comedy_pos_dict['NA'] = 0\n",
    "        comedy_pos_dict['NA'] += comedy_freq_dict[i][1]\n",
    "print(comedy_pos_dict)\n",
    "\n",
    "non_comedy_pos_dict = {}\n",
    "for i in non_comedy_freq_dict:\n",
    "    if non_comedy_freq_dict[i][0]:\n",
    "        if non_comedy_freq_dict[i][0] not in non_comedy_pos_dict:\n",
    "            non_comedy_pos_dict[non_comedy_freq_dict[i][0]] = 0\n",
    "        non_comedy_pos_dict[non_comedy_freq_dict[i][0]] += non_comedy_freq_dict[i][1]\n",
    "    else:\n",
    "        if 'NA' not in non_comedy_pos_dict:\n",
    "            non_comedy_pos_dict['NA'] = 0\n",
    "        non_comedy_pos_dict['NA'] += non_comedy_freq_dict[i][1]\n",
    "print(non_comedy_pos_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}